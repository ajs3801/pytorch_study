{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requires_grad=True와 관련된 내용\n",
    "\n",
    "https://gaussian37.github.io/dl-pytorch-gradient/\n",
    "\n",
    "PYTORCH 한국 사용자모임\n",
    "https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2191,  0.7855, -1.0553], requires_grad=True)\n",
      "tensor([2.2191, 2.7855, 0.9447], grad_fn=<AddBackward0>)\n",
      "tensor([ 9.8489, 15.5183,  1.7849], grad_fn=<MulBackward0>)\n",
      "tensor(9.0507, grad_fn=<MeanBackward0>)\n",
      "tensor([2.9588, 3.7140, 1.2596])\n"
     ]
    }
   ],
   "source": [
    "# set requires_grad to True value\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)     # requires grad's default value is False\n",
    "print(x)\n",
    "\n",
    "y = x + 2            # grad_fn=<AddBackward0>\n",
    "print(y)\n",
    "\n",
    "z = y*y*2            # grad_fn=<MulBackward0>\n",
    "print(z)\n",
    "\n",
    "z = z.mean()         # grad_fn=<MeanBackward0>}\n",
    "print(z)\n",
    "\n",
    "z.backward()         # dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9577,  0.6118, -1.0766], requires_grad=True)\n",
      "tensor([2.9577, 2.6118, 0.9234], grad_fn=<AddBackward0>)\n",
      "tensor([17.4965, 13.6432,  1.7054], grad_fn=<MulBackward0>)\n",
      "tensor([1.1831e+00, 1.0447e+01, 3.6937e-03])\n"
     ]
    }
   ],
   "source": [
    "# set requires_grad to True value\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)     # requires grad's default value is False\n",
    "print(x)\n",
    "\n",
    "y = x + 2            # grad_fn=<AddBackward0>\n",
    "print(y)\n",
    "\n",
    "z = y*y*2            # grad_fn=<MulBackward0>\n",
    "print(z)\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "\n",
    "z.backward(v)         # dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9247, -1.3332,  1.3784], requires_grad=True)\n",
      "tensor([ 1.9247, -1.3332,  1.3784])\n",
      "tensor([ 1.9247, -1.3332,  1.3784])\n",
      "tensor([3.9247, 0.6668, 3.3784])\n"
     ]
    }
   ],
   "source": [
    "# change requires gradient in the middle of code\n",
    "import torch\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)     # requires grad's default value is False\n",
    "print(x)\n",
    "\n",
    "# x.requires_grad_(False) -- 1\n",
    "# x.detach()              -- 2\n",
    "# with torch.no_grad():   -- 3\n",
    "\n",
    "# 1\n",
    "x.requires_grad_(False)\n",
    "print(x)\n",
    "\n",
    "# 2\n",
    "y = x.detach()\n",
    "print(y)\n",
    "\n",
    "# 3\n",
    "with torch.no_grad():\n",
    "    z = x + 2\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n",
      "tensor([12., 12., 12., 12.])\n",
      "tensor([15., 15., 15., 15.])\n",
      "tensor([18., 18., 18., 18.])\n"
     ]
    }
   ],
   "source": [
    "# gradient value accumulated\n",
    "\n",
    "import torch\n",
    "\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# gradient value accumulated\n",
    "# so erase the gradient value\n",
    "\n",
    "import torch\n",
    "\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m4\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/optim/sgd.py:27\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable, fused)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_supports_amp_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/optim/optimizer.py:270\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    268\u001b[0m         params \u001b[38;5;241m=\u001b[39m [params]\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams argument given to the optimizer should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man iterable of Tensors or dicts, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    272\u001b[0m                         torch\u001b[38;5;241m.\u001b[39mtypename(params))\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate: DefaultDict[torch\u001b[38;5;241m.\u001b[39mTensor, Any] \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "\n",
    "import torch\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(weights, lr=0.01)\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
